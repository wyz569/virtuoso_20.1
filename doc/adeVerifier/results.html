
<html><head><title>Managing Verification Results</title><meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="Approver" content="Technical Publications" />
<meta name="Author" content="rgirdhar" />
<meta name="CreateDate" content="2020-09-20" />
<meta name="CreateTime" content="1600633068" />
<meta name="DataType" content="Manuals" />
<meta name="Description" content="Describes how to use Virtuoso ADE Verifier." />
<meta name="DocTitle" content="Virtuoso ADE Verifier User Guide" />
<meta name="DocType" content="User Guide" />
<meta name="FileTitle" content="Managing Verification Results" />
<meta name="FileType" content="Chapter" />
<meta name="FMWikiRelease" content="FM-Wiki-3.2.1" />
<meta name="Keyword" content="adeVerifier" />
<meta name="Language" content="English" />
<meta name="ModifiedDate" content="2020-09-20" />
<meta name="ModifiedTime" content="1600633068" />
<meta name="NextFile" content="SLA_Verifier.html" />
<meta name="Group" content="ADE Verifier" />
<meta name="Platform" content="Custom IC Design" />
<meta name="PrevFile" content="simulate.html" />
<meta name="c_product" content="Virtuoso Analog Design Environment" />
<meta name="Product" content="Virtuoso Analog Design Environment" />
<meta name="ProductFamily" content="Virtuoso Analog Design Environment" />
<meta name="ProductVersion" content="ICADVM20.1" />
<meta name="RightsManagement" content="Copyright 2012-2020 Cadence Design Systems Inc." />
<meta name="Title" content="Virtuoso ADE Verifier User Guide -- Managing Verification Results" />
<meta name="Keywords" content="" />
<meta name="topic_type" content="" />
<meta name="reference_type" content="" />
<meta name="prod_feature" content="" />
<meta name="prod_subfeature" content="" />
<meta name="new_topic" content="No" />
<meta name="spotlight_topic" content="0" />
<meta name="Version" content="ICADVM20.1" />
<meta name="SpaceKey" content="adeVerifierICADVM201" />
<meta name="webflare-version" content="2.0" />
<link rel="stylesheet" href="styles/webflare.css" type="text/css" /></head><body style="background-color: #FFFFFF;"><a name="pagetop"></a>
<!-- Begin Buttons -->
<header><div class="docHeadr">Product Documentation<img src="icons/Cadence-Logo.jpg" /></div><nav class="blueHead"><ul><li><a class="content" href="adeVerifierTOC.html">Contents</a></li><li><a class="prev" href="simulate.html" title="Managing Implementation Runs">Managing Implementation Runs</a></li><li style="float: right;"><a class="viewPrint" href="adeVerifier.pdf">View/Print PDF</a></li><li style="float: right;margin-right: 25px;"><a class="nextd" href="SLA_Verifier.html" title="Verifying the Design Against the Specified Setup">Verifying the Design Against t ...</a></li></ul></nav></header>
<!-- End Buttons -->
<h5><center>Virtuoso ADE Verifier User Guide<br />Product Version ICADVM20.1, October 2020</center></h5><div id="main-content" style="min-height: 50vh; margin-left: 5%; margin-right: 2%;"><a name="#firstpage"></a>

<h1>6
<a id="pgfId-1073659"></a></h1>
<h1>
<a id="pgfId-1098066"></a><hr />
<a id="35423"></a>Managing Verification Results<hr />
</h1>

<p>
<a id="pgfId-1115488"></a><a id="results"></a>This chapter provides information on how you can access the verification status of your project managed through Virtuoso ADE Verifier (Verifier). It describes the following topics:</p>
<ul><li>
<a id="pgfId-1115518"></a><a href="results.html#56485">Understanding the Factors that Impact Verification Status</a></li><li>
<a id="pgfId-1116410"></a><a href="results.html#68648">Reviewing the Current Overall Verification Status</a></li><li>
<a id="pgfId-1115525"></a><a href="results.html#35692">Accessing the Verification Status of Requirements</a></li><li>
<a id="pgfId-1115711"></a><a href="results.html#26960">Signing off Requirements</a></li><li>
<a id="pgfId-1115737"></a><a href="results.html#41377">Reviewing the Detailed Verification Report</a></li></ul>




<p>
<a id="pgfId-1115490"></a> </p>
<table class="webflareTable" id="#id1115560">
<tbody><tr>
<td class="webflareTd" colspan="1" rowspan="1">
<h4><em>
<a id="pgfId-1115562"></a>Abstract</em></h4>

<p>
<a id="pgfId-1115565"></a>The status of your design verification project depends on various factors, such as the number of unmapped or missing requirements. For example, if your verification plan is incomplete, and the overall verification status is 100 percent, the verification project cannot be deemed as complete. </p>
<p>
<a id="pgfId-1119613"></a>You can access the overall verification status of your project, and drill down to the detailed status of each verification requirement in the project. You can generate various types of design verification reports. </p>
<p>
<a id="pgfId-1115976"></a>It is possible to manually override failed requirements by signing them off. You can also sign off the requirements of the type <em>Manual</em>. </p>

</td>
</tr>
</tbody></table>

<h2>
<a id="pgfId-1115640"></a><a id="56485"></a>Understanding the Factors that Impact Verification Status</h2>

<p>
<a id="pgfId-1117157"></a>The status of your design verification project depends on the following factors:</p>
<ul><li>
<a id="pgfId-1116383"></a>The number of mapped and unmapped requirements of the type <em>Spec Pass</em> or <em>Ran OK</em>.<br />
<a id="pgfId-1116384"></a>To get a realistic verification status, map all the requirements of the type <em>Spec Pass</em> or <em>Ran OK</em> to their implementations.</li><li>
<a id="pgfId-1124960"></a>The implementation output fails with <code>eval_err</code> for one or more sweep points. This indicates that some of the simulation points could not be finished correctly due to some error in ADE Explorer or ADE Assembler, such as a simulation error. The min/max values consider only the finished simulations results. Therefore, these values with errors should be used cautiously. <br />
<a id="pgfId-1125115"></a>The <em>Overall Status</em> reports also display the error information.<br />
<a id="pgfId-1125119"></a><div class="webflare-div-image">
<img width="668" height="350" src="images/results-2.gif" /></div></li><li>
<a id="pgfId-1116437"></a>The successful completion or failure of the implementation cellview runs.<br />
<a id="pgfId-1121926"></a>If an implementation cellview run fails, the associated requirements of the type <em>Ran OK</em> also fail verification. Additionally, the requirements mapped to the outputs of the cellview do not have results for verification checks.<br /><div class="webflare-information-macro webflare-macro-note">
<a id="pgfId-1121927"></a>When you run an implementation cellview, only the enabled tests of that cellview are run. The disabled tests are not run. The overall status of the requirements mapped to a disabled test or its outputs is <a href="results.html#39274"><em>No Results</em>, which impacts the verification project status.</a></div></li><li>
<a id="pgfId-1121928"></a>The results of the successful implementation cellview runs.<br />
<a id="pgfId-1116594"></a>Verifier compares the simulation result of an implementation output with the specification used by the mapped requirements. If the result meets the specification, the mapped requirements pass verification. Otherwise, they fail verification.</li><li>
<a id="pgfId-1116511"></a>The manual sign-off status of the failed requirements and the requirements of the type <em>Manual</em>.<br />
<a id="pgfId-1116512"></a>You can sign off the requirements of type <em>Manual</em>. Verifier also lets you sign off the requirements that failed verification, is not mapped to any implementation items or failed the specification check. Verifier considers signed off requirements as requirements that passed verification.<br />
<a id="pgfId-1116564"></a>For details on the manual sign-off feature, see <a href="results.html#26960">&#8220;Signing off Requirements&#8221;</a>.</li><li>
<a id="pgfId-1141797"></a>The metric prefix from specification units during verification. <br />
<a id="pgfId-1141918"></a>For details on metric prefix evaluation, see <a href="results.html#34665">&#8220;Evaluating the Metric Prefix&#8221;</a>.</li><li>
<a id="pgfId-1145084"></a>The output expressions for implementations. If an output has no expressions specified in ADE Assembler, the <em>Overall Status </em>shows &#39;No Results&#39;. </li></ul>


















<p>
<a id="pgfId-1116659"></a>Changes in these factors impact the overall design verification status. For example, if you sign off some failed requirements, the percentage of the overall verification progress increases.</p>
<p>
<a id="pgfId-1117174"></a>The verification failures can include requirements that are not mapped, mapped implementations that are not simulated or do not have results, failed specification checks, and cases where simulation results did not match the specifications.</p>

<h3>
<a id="pgfId-1116704"></a><a id="92550"></a>Saving and Lo<a id="saveLoadRunSummary"></a>ading the Run Summary Data</h3>

<p>
<a id="pgfId-1154975"></a>Verifier stores the run summary data (PALS) file as <code>.xml</code> files in separate locations, based on whether the cellview is editable or read-only. </p>
<ul><li>
<a id="pgfId-1154734"></a>When the cellview is editable, Verifier stores the run summary data of a local or referenced implementation in the <code>results</code> directory of the current cellview. </li><li>
<a id="pgfId-1154829"></a>When the cellview is read-only, Verifier stores the run summary data in the following locations:<ul><li>
<a id="pgfId-1154563"></a>For a local implementation: &lt;<span class="webflare-courier-new" style="white-space:pre"><em>project directory</em></span>&gt;/&lt;<span class="webflare-courier-new" style="white-space:pre"><em>library</em></span>&gt;/&lt;<span class="webflare-courier-new" style="white-space:pre"><em>cell</em></span>&gt;/&lt;<span class="webflare-courier-new" style="white-space:pre"><em>view</em></span>&gt;/&lt;<span class="webflare-courier-new" style="white-space:pre"><em>results</em></span>&gt;</li><li>
<a id="pgfId-1154721"></a>For a referenced implementation &#8211; &lt;<span class="webflare-courier-new" style="white-space:pre"><em>project directory</em></span>&gt;/&lt;<span class="webflare-courier-new" style="white-space:pre"><em>ref_library</em></span>&gt;/&lt;<span class="webflare-courier-new" style="white-space:pre"><em>ref_cell</em></span>&gt;/&lt;<span class="webflare-courier-new" style="white-space:pre"><em>ref_view</em></span>&gt;/&lt;<span class="webflare-courier-new" style="white-space:pre"><em>results</em></span>&gt;<br />
<a id="pgfId-1155360"></a>To know more about project directories, see <a href="implementations.html#23464">Project Directory Setup</a>.</li></ul></li></ul>






<p>
<a id="pgfId-1155440"></a>When you open an existing Verifier cellview or update a referenced cellview, Verifier loads the existing and last modified run summary data file from the default <code>results</code> directory in the current cellview or from these locations. </p>

<h3>
<a id="pgfId-1141688"></a><a id="34665"></a>Evaluating the Metric Pr<a id="SpecMismatch"></a>efix</h3>

<p>
<a id="pgfId-1142342"></a>You can check for any mismatch in the implementation specifications with the requirement specifications mapped to that implementation. This happens when the <em>Requirement specification and check to implementation</em> option is set in the preferences. </p>
<p>
<a id="pgfId-1142360"></a>However, by default this check only evaluates the specification numbers and the unit. It does not do any calculations to check if the value and unit combination matches. </p>

<p><strong>Example 6-1
<a id="pgfId-1142595"></a></strong></p>
<pre class="webflare-courier-new codeContent">
<a id="pgfId-1142660"></a>Requirement: MaxSpec = 10m, unit = V;</pre>
<pre class="webflare-courier-new codeContent">
<a id="pgfId-1142361"></a>Implementation: MaxSpec = 10, unit = mV;</pre>

<p>
<a id="pgfId-1142362"></a>This will be flagged as a mismatch. </p>
<p>
<a id="pgfId-1142314"></a>To check for such matches or mismatches, enable the preference option <em>Evaluate metric prefix</em> on the <em>General</em> tab. </p>
<div class="webflare-information-macro webflare-macro-note">
<a id="pgfId-1142821"></a>The <em>Evaluate metric prefix</em> option is hidden when the <em>Specification Search Order</em> is set to <em>Implementation Specification </em>because no check for specification is performed in such cases.</div>

<p><strong>Example 6-2
<a id="pgfId-1142680"></a></strong></p>

<p>
<a id="pgfId-1141690"></a>Enable <em>Check unit</em>, <em>Evaluate metric prefix</em> and use <em>Requirement specification with check</em> in the <em>Preferences</em> form. The metric prefix of the requirement specification unit is used for both specification check and evaluation. Assume that the values are as follows: </p>
<p>
<a id="pgfId-1141691"></a>Requirement: MaxSpec = 10m, unit = V;</p>
<p>
<a id="pgfId-1141692"></a>Implementation: MaxSpec = 10, unit = mV, Implementation results: minValue = 1.5, maxValue = 5.5;</p>
<p>
<a id="pgfId-1141693"></a>When evaluation is done, the status is: </p>
<p>
<a id="pgfId-1141694"></a>Spec Check: Pass (10m V == 10 mV); </p>
<p>
<a id="pgfId-998398"></a>No specification error is reported. The unit of the requirements is used for the displayed results. </p>
<p>
<a id="pgfId-1141695"></a>Result status shown: Verification: OverallStatus = Pass, MinValue = 1.5m, MaxValue = 5.5m , Unit = v. <br /></p>

<div class="webflare-div-image">
<img width="668" height="147" src="images/results-3.gif" /></div>

<p>
<a id="pgfId-1141701"></a>In the above illustration, the units are different in the requirement and implementation specifications. When you enable <em>Evaluate metric prefix</em>, the specification check is &#39;pass&#39; as the numerical values are identical when the unit prefix is considered. </p>
<p>
<a id="pgfId-1141683"></a>You can also enable the <em>Evaluate metric prefix</em> preference by using the environment variable <a href="app_envar.html#99460">evaluateMetricPrefix</a>. </p>
<p>
<a id="pgfId-1143025"></a>The <em>Evaluate metric prefix</em> preference only checks the first single prefix, such as:</p>
<p>
<a id="pgfId-1143027"></a><code>Y|Z|E|P|T|G|M|K(?!elvin)|k(?!ilo)|%|m(?!il|persec)|u|Âµ|n|p|f|a|z|y</code></p>
<div class="webflare-information-macro webflare-macro-note">
<a id="pgfId-1143143"></a>Here the supported prefix is<code> K</code> but not <code>Kelvin</code>; <code>k</code> but not <code>kilo</code>; <code>m</code> but not <code>mil</code> or <code>mpersec</code>. Except the above prefixes, complex combinations are not supported.</div>

<h2>
<a id="pgfId-1116365"></a><a id="68648"></a>Reviewing the Current Overall Verification Status</h2>

<p>
<a id="pgfId-1116060"></a>As illustrated in the following figure, Verifier displays the current overall design verification status of your project on the <em>Overall Progress</em> bar. You can view further details in the status tooltip.</p>

<p>
<a id="pgfId-1116771"></a></p>
<div class="webflare-div-image">
<img width="663" height="213" src="images/results-4.gif" /></div>

<p>
<a id="pgfId-1115105"></a>To display the overall verification status, if it is not already displayed<a id="status"></a>: </p>

<ul><li>
<a id="pgfId-1115106"></a>Choose <em>Overall Progress </em>on the toolbar.<br />
<a id="pgfId-1115109"></a>The current overall verification status displays with the <em>pass</em>, <em>fail</em>, and <em>unmapped</em> percentage.</li></ul>


<p>
<a id="pgfId-1115113"></a>To display the status snapshot tip:</p>

<ul><li>
<a id="pgfId-1116828"></a>Place the pointer over the required segment on the <em>Overall Progress</em> bar.</li></ul>

<p>
<a id="pgfId-1116930"></a>The status snapshot tip includes the following information:</p>
<ul><li>
<a id="pgfId-1116931"></a>Requirements information, including the total number of mapped, unmapped, and manual requirements.</li><li>
<a id="pgfId-1116932"></a>The status of the implementation runs.</li><li>
<a id="pgfId-1116942"></a>The percentage of requirements that passed verification, along with the number of failed and unmapped requirements, and requirements that do not have results for determining their verification status.</li></ul>


<p>
<a id="pgfId-1120591"></a><strong>Note:</strong></p>
<ul><li>
<a id="pgfId-1120388"></a>The percentage for <em>pass</em> rate is rounded down whereas the percentage for <em>fail</em>, <em>unmapped</em>, and <em>no results</em> is rounded up. This ensures that the rounding does not lead to overly optimistic view of the results. <br />
<a id="pgfId-1139591"></a>For example: <ul><li>
<a id="pgfId-1139607"></a>99.8% <em>pass</em> is not rounded off as 100% <em>pass</em>. </li><li>
<a id="pgfId-1139616"></a><em>Pass</em> rate: 34.899%, <em>fail</em> rate: 64.1%, <em>unmapped</em>: 1.001% - Here, the rounded values are shown as <em>pass</em>: 34% and <em>fail</em> rate: 65% and <em>unmapped</em>: 2%. </li></ul><br />
<a id="pgfId-1139789"></a>As a result of the rounding schema used, the sum of all values may deviate from 100%, as shown in the above example. </li><li>
<a id="pgfId-1139340"></a>To specify the rounding schema for the calculation of<em> Overall Progress,</em> <em>OverallStatus, MinValue</em>, <em>TypicalValue</em>, and <em>MaxValue</em> on the <em>Results</em> tab, set the <a href="app_envar.html#81090">significantDigits</a> environment variable.<br /><div class="webflare-information-macro webflare-macro-note">
<a id="pgfId-1140774"></a>The calculated values are shown as per the rounding schema selected in the <em>Overall Progress</em> bar. However, the values displayed in the tool tips are based on the calculation (<code>significantDigits</code>+1). For example, when <code>significantDigits</code> is set to 2, the pass rate of 34.899% will be displayed as 34% in the <em>Overall Progress </em>bar and 34.8% in the corresponding tool tip.</div>
<a id="pgfId-1139891"></a>You can observe the following illustrations to understand the calculation of<em> </em>values on the <em>Overall Progress</em> bar using the rounding schema:<ul><li>
<a id="pgfId-1140886"></a>When <code>significantDigits</code> is set to default value:<br /><div class="webflare-div-image">
<img width="653" height="156" src="images/results-5.gif" /></div>
<a id="pgfId-1140906"></a>Setting <code>significantDigits</code> to 4 means that the <em>Overall Progress</em> and <em>OverallStatus</em> are calculated by using default value. </li><li>
<a id="pgfId-1140059"></a>When <code>significantDigits</code> is set to 2:  <br /><div class="webflare-div-image">
<img width="655" height="156" src="images/results-6.gif" /></div>
<a id="pgfId-1144978"></a>Setting <code>significantDigits</code> to 2 calculates <code>100%</code> as &#39;<code>1e+2%</code>&#39;. </li></ul></li><li>
<a id="pgfId-1139358"></a>Referenced requirements owned by other owners, and not the current user, are excluded from the overall verification progress bar and tool tip. Manual requirements are excluded from the mapped and unmapped requirements count.<br /><div class="webflare-information-macro webflare-macro-tip">
<a id="pgfId-1116970"></a>
Click the <em>Setup</em> tab and the right and left pane titles display the overall mapping percentage of the implementations and requirements, respectively.</div></li></ul>




















<h3>
<a id="pgfId-1147669"></a><a id="24265"></a>Understanding Overall Progress, Coverage, and Overall Coverage</h3>

<p>
<a id="pgfId-1147734"></a>There might be instances when you see a difference in the <code>Pass</code> and <code>Fail</code> percentages in the values shown for <em>Overall Progress</em> and <em>Overall Coverage</em> on the Verifier toolbar. </p>
<p>
<a id="pgfId-1147974"></a>The calculation for <em>Overall Progress</em> is based on the number of requirements. For example, the following illustration shows the tooltip as &quot;<code>14 out of 23 pass</code>&quot;.</p>
<p>
<a id="pgfId-1148166"></a> </p>

<div class="webflare-div-image">
<img width="668" height="67" src="images/results-8.gif" /></div>

<p>
<a id="pgfId-1148163"></a>In this example, the total number of requirements with results is <code>23</code>, and the number of requirements that have passed is <code>14</code>. The <em>Overall Progress </em>considers only the requirements that have passed or failed. </p>
<p>
<a id="pgfId-1148528"></a><em>Coverage</em> in Verifier is calculated by considering all the design point combinations that are added to verification spaces and available in the implementation history. The coverage values are reported as &quot;<code>x% passed, y% failed</code>&quot;, which can be interpreted as: </p>
<p>
<a id="pgfId-1148531"></a><code>x% </code>design points from SPACE are<code> pass -- </code>Green</p>
<p>
<a id="pgfId-1148532"></a><code>y% </code>design points from SPACE are<code> fail -- </code>Red</p>
<p>
<a id="pgfId-1148533"></a><code>(100%-(x+y)%) </code>design points from SPACE are<code> not covered -- </code>Grey</p>
<div class="webflare-information-macro webflare-macro-note">
<a id="pgfId-1153283"></a>If a design variable defined in a verification space, that is assigned to an implementation, is not needed for simulation then Verifier ignores this variable for calculating the overall coverage. </div>
<p>
<a id="pgfId-1148508"></a>The <em>Overall Coverage</em> value is calculated by considering all the design points specified in the verification spaces and reporting these points as <code>Pass</code>, <code>Fail</code>, or <code>No Coverage</code>. </p>
<p>
<a id="pgfId-1149413"></a>Consider the following illustration that shows the tooltip as &quot;<code>4 out of 45 pass</code>&quot;. </p>
<p>
<a id="pgfId-1148972"></a> </p>

<div class="webflare-div-image">
<img width="668" height="65" src="images/results-9.gif" /></div>

<p>
<a id="pgfId-1149520"></a>In this example, the total number of design points is <code>45</code>, and the number of points that have passed is <code>4</code>. The 45 design points include points that are defined in the verification space, as well as those points that are not defined in verification spaces but simulated during a run. The 4 points that show as <code>pass</code> are those points that are successfully implemented or covered. </p>
<p>
<a id="pgfId-1150161"></a><a id="designPointsCoverage"></a>When you select the <em>Overall Coverage</em> progress bar, the <em>OverallStatus</em>, <em>MinValue</em>, and <em>MaxValue</em> values are updated. Calculation of these values is based only on the design points specified in the assigned verification space. All other design points are ignored. </p>
<p>
<a id="pgfId-1150162"></a>For example, consider the following Setup Library shown in the following illustration: </p>
<p>
<a id="pgfId-1150166"></a></p>

<div class="webflare-div-image">
<img width="306" height="390" src="images/results-10.gif" /></div>

<p>
<a id="pgfId-1150167"></a>Based on the design points defined in this library, the <em>OverallStatus</em>, <em>MinValue</em>, and <em>MaxValue</em> are as follows: </p>
<p>
<a id="pgfId-1150171"></a></p>

<div class="webflare-div-image">
<img width="668" height="250" src="images/results-11.gif" /></div>

<p>
<a id="pgfId-1150172"></a>Selecting the option <em>Show results for Verification Space parameter conditions</em> ensures that Verifier calculates the coverage based on design points from verification spaces for all subsequent simulations. Additionally, this preference ensures the following: </p>
<ul><li>
<a id="pgfId-1150221"></a>The Verifier toolbar always shows the <em>Overall Coverage </em>progress bar when you close and reopen the Verifier cellview. </li><li>
<a id="pgfId-1150233"></a>Clicking the <em>Update Coverage </em>button on the Verifier toolbar updates the <em>MinValue</em>, <em>MaxValue</em>, <em>TypicalValue,</em> and <em>OverallStatus</em> values. </li><li>
<a id="pgfId-1151142"></a>The <em>TypicalValue</em> column shows a value if a typical design point falls in the range of values specified in a verification space. If there are multiple typical design points, the column shows <code>various</code>. If there is no typical design point, the cell is empty. </li></ul>



<h2>
<a id="pgfId-1115133"></a><a id="35692"></a>Accessing the Verification Status of Requirements<a id="verifStatusOfReq"></a></h2>
<p>
<a id="pgfId-1117999"></a>In a requirements-driven verification flow, it is important to review the status of each requirement to identify the requirements that need attention. You can access the verification results of each requirements in Verifier. You can also filter the requirements hierarchy based on the verification results. </p>
<p>
<a id="pgfId-1118011"></a>Typically, you investigate the failed requirements to determine the corrective actions. You can make appropriate changes to the design so that the results meet the specifications, and re-simulate the implementation cellview. Alternatively, if the specifications have scope for updates, you can change the specifications in the implementation cellview and the requirement so that the results are within the new specifications. To facilitate such actions, Verifier lets you view simulation results and edit the implementation cellview in the default application of that cellview. </p>
<p>
<a id="pgfId-1119762"></a>When you investigate the verification status, you can also consider making appropriate changes to your verification plan to achieve your design verification goals and quality parameters. For example, you can choose to make the plan more granular by adding new requirements and mapping them with their implementations, or change the specifications of some requirements. </p>
<div class="webflare-information-macro webflare-macro-tip">
<a id="pgfId-1117249"></a>
Typically, the goal of a verification project is to achieve 100 percent overall verification status. However, you can consider to tape out when your verification status is 95 percent after a careful analysis and a good understanding of the missing 5 percent of the verification objectives. By analyzing the verification status of the requirements in Verifier, you can achieve this understanding. If required, you can choose to <a href="results.html#signoff">manually override</a> those 5 percent of requirements.</div>
<p>
<a id="pgfId-1119863"></a>The following figure illustrates how you can identify the verification status and get relevant details from the <em>Results</em> tab.</p>
<p>
<a id="pgfId-1117274"></a></p>
<div class="webflare-div-image">
<img width="668" height="472" src="images/results-12.gif" /></div>

<p>
<a id="pgfId-1115134"></a>The <em>Results</em> tab displays the following columns: </p>
<ul><li>
<a id="pgfId-1123290"></a><a href="requirements.html#14288"><em>Hier</em></a></li><li>
<a id="pgfId-1123311"></a><a href="requirements.html#58724"><em>Title</em></a></li><li>
<a id="pgfId-1123336"></a><a href="requirements.html#23298"><em>MinSpec</em></a></li><li>
<a id="pgfId-1124530"></a><a href="requirements.html#92531"><em>MaxSpec</em></a></li><li>
<a id="pgfId-1152342"></a><a href="requirements.html#79067"><em>Unit</em></a></li><li>
<a id="pgfId-1124532"></a><em><a actuate="user" class="URL" href="../adeVerifier/results.html#overallStatus" show="replace" xml:link="simple">Overall Status</a></em></li><li>
<a id="pgfId-1124695"></a>MinValue - Shows the overall minimum value for multiple mappings. </li><li>
<a id="pgfId-1126028"></a><em>TypicalValue</em><a id="TypicalValue"></a> - Shows the typical value for the mapped output according to the typical settings in <em>Tools </em>&#8211; <em>Typical Value Setup</em>. A blank indicates no matched point is found or the requirement is not mapped to the output. <code>various</code> indicates there are multiple matched points or the mapped output has a different typical value. <br />
<a id="pgfId-1126762"></a><div class="webflare-div-image">
<img width="668" height="267" src="images/results-13.gif" /></div>
<a id="pgfId-1126773"></a>Verifier allows you to set up the typical and get the value from unique matched point. The typical value is derived by selecting one value out of the matrix of corner and sweep values and matching the specified &#39;typical&#39; parameters inside Verifier. For each mapped requirement, Verifier analyzes implementation results and chooses one result value from the corner or sweep values being specified. This value is used as the &#39;typical&#39; value in Verifier. If matching sweep or corner parameter is not found, the <em>TypicalValue </em>column can be left blank. Similarly, the column is left blank if multiple values are found, which match the typical parameters. In this case, modify the typical setting accordingly so that a unique match is found. Typical values are not used for Monte Carlo implementations or when more than one implementations are mapped to one requirement.<br />
<a id="pgfId-1125777"></a><div class="webflare-div-image">
<img width="668" height="305" src="images/results-14.gif" /></div></li><li>
<a id="pgfId-1124606"></a>MaxValue- Shows the overall maximum value for multiple mappings. </li><li>
<a id="pgfId-1134980"></a><em><a actuate="user" class="URL" href="../adeVerifier/SLA_Verifier.html#Coverage" show="replace" xml:link="simple">Coverage</a></em> </li></ul>


















<p>
<a id="pgfId-1134522"></a>Th<a id="resultsOptional"></a>e Results tab can display the following optional columns:</p>
<ul><li>
<a id="pgfId-1134839"></a><a href="requirements.html#51466"><em>ID</em></a></li><li>
<a id="pgfId-1134857"></a><a href="requirements.html#93304"><em>Type</em></a></li><li>
<a id="pgfId-1152374"></a><a href="requirements.html#46096"><em>VerificationSpace</em></a></li><li>
<a id="pgfId-1134966"></a><a href="requirements.html#16818"><em>Owner</em></a></li><li>
<a id="pgfId-1152398"></a><a href="requirements.html#78885"><em>CellviewHolder</em></a></li><li>
<a id="pgfId-1152413"></a><a href="requirements.html#79243"><em>Scope</em></a></li><li>
<a id="pgfId-1152421"></a><a href="requirements.html#88836"><em>Domain</em></a></li><li>
<a id="pgfId-1152429"></a><a href="requirements.html#11291"><em>Description</em></a></li><li>
<a id="pgfId-1152461"></a><a href="requirements.html#17744"><em>ReadOnly</em></a></li><li>
<a id="pgfId-1151413"></a><a href="app_forms.html#51929"><em>Yield</em> </a></li><li>
<a id="pgfId-1151421"></a><a href="app_forms.html#42726"><em>Min</em></a></li><li>
<a id="pgfId-1151475"></a><a href="app_forms.html#87438"><em>Max</em> </a></li><li>
<a id="pgfId-1151479"></a><a href="app_forms.html#53173"><em>Mean</em></a></li><li>
<a id="pgfId-1151483"></a><a href="app_forms.html#58537"><em>StandardDeviation</em></a></li><li>
<a id="pgfId-1151494"></a><a href="app_forms.html#72353"><em>SigmaToTarget</em></a></li><li>
<a id="pgfId-1151498"></a><a href="app_forms.html#15443"><em>Cpk</em> 
</a><br /><div class="webflare-div-image">
<img width="668" height="347" src="images/results-15.gif" /></div></li></ul>


















<div class="webflare-information-macro webflare-macro-note">
<a id="pgfId-1152663"></a>In case of Monte Carlo runs with sweeps or <em>SigmaToTarget </em>values defined with range specifications, you can get different <em>Min</em> or <em>Max</em> values for each statistical value. In such scenarios, the values are displayed as &lt;<span class="webflare-courier-new" style="white-space:pre"><em>minValue</em></span>&gt;, &lt;<span class="webflare-courier-new" style="white-space:pre"><em>maxValue</em></span>&gt; values. In all other cases, the <em>Min</em> and <em>Max</em> values remain the same, and show a single value that uses the same notation as the requirement specifications. You can also use the <a href="app_envar.html#27450">calcStatisticsForNonMC</a> environment variable to save or load the statistical values to or from the run summary data file. In case of Monte Carlo runs, the statistical values are always non-empty. </div>
<p>
<a id="pgfId-1134819"></a>To view these optional columns, right-click anywhere in the Results tab header row, and select the required columns.</p>
<p>
<a id="pgfId-1134313"></a>To view additional details related to the implementations mapped to the requirements, right-click anywhere in the Results tab, choose <em>Show</em>, and select the filter options as required. </p>
<p>
<a id="pgfId-1123782"></a>The Results tab also displays the detailed verification results of the selected requirement in the Information assistant, as well as the corresponding requirement details in the Requirement Editor Assistant.</p>
<p>
<a id="pgfId-1142943"></a>You can show or hide the columns of the requirements list in the <em>Results</em> tab. For this, right-click anywhere on the column heading in the results area and select the columns you want to show. Verifier hides the columns that are not selected.</p>
<p>
<a id="pgfId-1142939"></a>To s<a id="resultsSort"></a>ort columns, you can use the drag-and-drop method and change the display of columns. Additionally, you can specify the default column order and hidden columns by using the environment variables <a href="app_envar.html#12117">resColumnOrder</a> and <a href="app_envar.html#33780">resHiddenColumns</a>. </p>

<h3>
<a id="pgfId-1123699"></a>Verification Results in the Information Assistant and Requirement Editor</h3>

<p>
<a id="pgfId-1131034"></a>The following figure illustrates how you can review the verification results of a requirement in the Information assistant and Requirement Editor: </p>

<p>
<a id="pgfId-1131038"></a></p>
<div class="webflare-div-image">
<img width="668" height="415" src="images/results-16.gif" /></div>
<ul><li>
<a id="pgfId-1131047"></a>Select the requirement in the Results tab. <ul><li>
<a id="pgfId-1132818"></a>The Information assistant displays the requirements hierarchy with the verification status and details such as type, status for the requirement, specifications, histories, minimum value, maximum value for the corresponding implementation. For more details, see <a href="simulate.html#22244">Viewing Run Results Using the Information Assistant</a>. </li><li>
<a id="pgfId-1133524"></a>The Requirement Editor displays the requirement currently selected in the Results tab. You can make required changes to your verification plan to achieve your design verification goals. These changes can be made to either one of requirements or implementations. </li></ul></li></ul>



<p>
<a id="pgfId-1123469"></a>T<a id="overallStatus"></a>he following table lists the keywords and icons used to indicate the verification status of requirements. The icons display with the hierarchical numbers, and the keywords display in the <em>Overall Status</em> column. </p>
<table class="webflareTable" id="#id1123470">
<tbody><tr>
<th class="webflareTh" colspan="1" rowspan="1">
<span class="tbl-head" id="#id1123472">
<a id="pgfId-1123472"></a>Icon</span>
</th>
<th class="webflareTh" colspan="1" rowspan="1">
<span class="tbl-head" id="#id1123474">
<a id="pgfId-1123474"></a>Keywords</span>
</th>
<th class="webflareTh" colspan="1" rowspan="1">
<span class="tbl-head" id="#id1123476">
<a id="pgfId-1123476"></a>Description</span>
</th>
</tr>
<tr>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123481"></a><em><img width="26" height="25" src="images/results-17.gif" />
</em></p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123483"></a>Pass</p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123485"></a>The requirement passed verification.</p>

<div class="webflare-information-macro webflare-macro-note">
<a id="pgfId-1156868"></a>If a requirement is mapped to multiple implementation outputs, the <em>OverallStatus</em> column shows Pass as its status only when all implementation outputs mapped to it have also passed. </div>

</td>
</tr>
<tr>
<td class="webflareTd" colspan="1" rowspan="3">
<p>
<a id="pgfId-1123490"></a><em><img width="25" height="27" src="images/results-18.gif" />
</em></p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123492"></a>Fail </p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123494"></a>The requirement failed verification</p>
</td>
</tr>
<tr>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123498"></a>Signoff Required</p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123500"></a>The requirement is of the type <em>Manual</em> and it is not signed off.</p>
</td>
</tr>
<tr>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123504"></a>Not Run</p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123506"></a>The implementation mapped to the requirement has not been run and must be run to capture simulation results.</p>
</td>
</tr>
<tr>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123511"></a><em><img width="29" height="28" src="images/results-19.gif" />
</em></p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123513"></a>Spec Check Fail</p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123515"></a>The specification checks failed for the requirement. </p>
<p>
<a id="pgfId-1123517"></a>For details, see the corresponding <h-hot><a href="requirements.html#specFail">requirement icon</a></h-hot>.</p>
</td>
</tr>
<tr>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123522"></a><em><img width="25" height="23" src="images/results-20.gif" />
</em></p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123524"></a>Not Mapped</p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123526"></a>The requirement of the type <em>Ran OK</em> or <em>Spec Pass</em> is not mapped to any implementation. It needs to be mapped to its corresponding implementation.</p>
</td>
</tr>
<tr>
<td class="webflareTd" colspan="1" rowspan="2">
<p>
<a id="pgfId-1123531"></a><em><img width="25" height="23" src="images/results-21.gif" />
</em></p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123534"></a>No Results<a id="39274"></a> </p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123536"></a>Verifier does not have the simulation results of the implementations associated with the requirement.</p>
</td>
</tr>
<tr>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123540"></a>Test Disabled</p>
</td>
<td class="webflareTd" colspan="1" rowspan="1">
<p>
<a id="pgfId-1123542"></a>The test mapped to the requirement is disabled in the implementation cellview or the specified history, and cannot be run.</p>
</td>
</tr>
</tbody></table>
<ol><li>
<a id="pgfId-1123543"></a>Select a requirement to view its verification details in the <em>Information</em> assistant.<br />
<a id="pgfId-1122171"></a>You can copy the value of a field in the assistant. For this, right-click the result field and choose <em>Copy String</em>. You can also select the field and press <code>Ctrl+C</code> to copy the text.<br />
<a id="pgfId-1122172"></a>To view the mapped implementation, along with its specification and simulation status, select the <em>Details</em> check box.</li></ol>


<p>
<a id="pgfId-1122173"></a>For requirements that have passed verification, the results meet the specifications.</p>
<p>
<a id="pgfId-1117307"></a>To filter the requirements based on overall status:</p>

<ul><li>
<a id="pgfId-1117323"></a>Click <em>Show</em> and select the filter options as required. <br />
<a id="pgfId-1117349"></a>For example, if you want to hide the requirements that are not mapped, ensure that <em>Unmapped</em> is not selected. The hidden requirements are indicated next to the overall progress bar.</li></ul>


<p>
<a id="pgfId-1117768"></a>To open the implementation cellview mapped with a requirement:</p>

<ul><li>
<a id="pgfId-1117896"></a>Right-click the requirement and choose <em>Edit Implementation Cellview</em>.<br />
<a id="pgfId-1117926"></a>The implementation cellview opens in edit mode in its default application.</li></ul>



<h2>
<a id="pgfId-1117890"></a><a id="26960"></a>Signing off Requirements<a id="signoff"></a></h2>

<p>
<a id="pgfId-1127147"></a>You can sign off the requirements of the type <em>Manual</em>. Verifier also lets you sign off requirements that have overall status as <code>Fail</code>, <code>Not Mapped</code>, <code>Spec Check Fail</code>, or <code>Signed Off</code>. Verifier considers signed off requirements as requirements that passed verification. Therefore, when you sign off a requirement, the overall verification progress percentage increases.</p>
<p>
<a id="pgfId-1118442"></a>The procedure to sign off the failed, unmapped, or spec check failed requirements is similar to signing off a requirement of the type <em>Manual</em>. After signing off a requirement, you can select it in the requirements hierarchy of the <em>Results</em> tab and review the signoff details in the <em>Information</em> assistant. It is possible to specify the validity period of a requirement signoff. For example, you can choose to retain the signoff indefinitely or for a specific period. </p>
<p>
<a id="pgfId-1118170"></a>The signed off requirements are documented in the verification reports. For details on these reports, see <a href="results.html#41377">&#8220;Reviewing the Detailed Verification Report&#8221;</a>.</p>
<div class="webflare-information-macro webflare-macro-note">
<a id="pgfId-1120675"></a>When you change the mapping of a signed off requirement, the signoff gets removed because it loses relevance with the new map.</div>
<p>
<a id="pgfId-1118675"></a>The following figure illustrates how you can sign off a failed requirement.</p>

<p>
<a id="pgfId-1115847"></a></p>
<div class="webflare-div-image">
<img width="670" height="638" src="images/results-22.gif" /></div>

<p>
<a id="pgfId-1115848"></a>To sign off a failed requirement</p>
<ol><li>
<a id="pgfId-1115849"></a>In the <em>Results</em> tab, right-click the failed requirement and select <em>Signoff</em>.<br />
<a id="pgfId-1115850"></a>The <a href="app_forms.html#94897">Sign Off</a> form displays.</li><li>
<a id="pgfId-1115851"></a>Type a name in the <em>User</em> <em>Name</em> field.</li><li>
<a id="pgfId-1115853"></a>Specify the valid period of the signoff from the <em>Lifetime of Signoff</em> drop-down list. The available options are:<ul><li>
<a id="pgfId-1115854"></a><em>Once</em>: The signoff is valid only for a specific set of simulation results and will become disabled when newer simulation results become available.</li><li>
<a id="pgfId-1115855"></a><em>Indefinitely</em>: The signoff is valid for an infinite time.</li><li>
<a id="pgfId-1115856"></a><em>Until Date</em>: The signoff is valid up to the date specified in the corresponding field.</li></ul></li><li>
<a id="pgfId-1145354"></a>Specify if sign off information is stored after applying, or without applying the signoff to the requirement. </li><li>
<a id="pgfId-1115852"></a>Type details of the signoff, such as the reason, in the <em>Comments</em> field.</li><li>
<a id="pgfId-1128015"></a>Click <em>OK</em>.</li></ol>









<p>
<a id="pgfId-1128016"></a>The status of the requirement changes to <em>Signed Off</em>. </p>

<b>Important:</b><br />
<a id="pgfId-1144192"></a>


<ul><li style="list-style-type: none;background-image: none;"><ul><li>
<a id="pgfId-1128026"></a>In a multi-user verification setup, only the requirement owners can sign off their requirements in the owner cellviews. The project manager can review the sign-off details from the master cellview, but cannot sign off the requirements. See <a href="multiUserSetup.html#12039">&#8220;Synchronization Between the Master and Referenced Cellviews&#8221;</a>.</li><li>
<a id="pgfId-1144205"></a>Specifying the sign off lifetime as &#39;Once&#39; for a requirement essentially means that the signoff is valid only for the current simulation results. However, an unmapped requirement does not generate results. Therefore, the requirement with sign off set to &#39;Once&#39; may continue to remain signed off unless it is mapped to an implementation. </li></ul></li></ul>


<h3>
<a id="pgfId-1146283"></a>Updating the Progress Manually </h3>

<p>
<a id="pgfId-1146560"></a>In the Sign Off form, you can add or update the completion percentage for requirements of type <em>Manual</em> . This indicates that verification is in progress, but not complete. </p>
<p>
<a id="pgfId-1146718"></a>To add the completion percentage for a <em>Manual</em> requirement:</p>
<ol><li>
<a id="pgfId-1146777"></a>Select the <em>Percentage Complete </em>check box. This enables a list box and a slider.</li><li>
<a id="pgfId-1146906"></a>Do one of the following: <br />
<a id="pgfId-1146961"></a>&#8211; In the list box, select the percentage of completion progress that you want to specify. <br />
<a id="pgfId-1147117"></a>&#8211; Move the slider to select the completion percentage that you want to specify. <br />
<a id="pgfId-1146961"></a>The specified percentage is used to calculate the status of <em>Manual </em>requirements and also impacts the staus of <em>Note</em> requirements. Both these values are shown in the <em>OverallStatus</em> column. For example, if you specify the completion percentage as 50%, the requirement shows in the <em>Results</em> tab with <code>50%</code> value for<em> OverallStatus</em>. If you specify the value as <code>100%</code> then the requirement status shows <em>Signed Off</em>, and if you specify <code>0%</code>, the status shows as <em>Fail</em>.</li></ol>




<div class="webflare-information-macro webflare-macro-note">
<a id="pgfId-1146556"></a>You can select either <em>Sign Off</em> or <em>Percentage Complete </em>to specify the sign off for your requirements. When you select the <em>Percentage Complete </em>check box, the <em>Sign Off</em> radio options are disabled. A percentage value less than 100% is still considered as a <code>Fail</code> for the overall status of the requirements. If you move the percentage to 100%, the requirement status automatically shows as <code>Pass</code>. </div>

<h2>
<a id="pgfId-1115702"></a><a id="41377"></a>Reviewing the Detailed Verification Report</h2>

<p>
<a id="pgfId-1118820"></a>Verifier presents detailed requirements-based verification reports in HTML formats. These reports contain the overall verification status and the verification details of each requirement, including the mapped implementations and verification results.</p>
<p>
<a id="pgfId-1118990"></a>Verifier stores these reports in the current directory using the naming format <span class="webflare-courier-new" style="white-space:pre"><em>view_name.extension</em></span>. For example, <code>TOP_verification.html</code>. If required, you can set Verifier to store the reports at the location of your choice. You can also specify different names for the reports.</p>
<p>
<a id="pgfId-1118849"></a>By default, Verifier displays the HTML report in the default web browser. You can set the <a href="app_forms.html#37011"><em>Report Options</em> from the Preferences form.</a></p>

<div class="webflare-information-macro webflare-macro-information">
<a id="pgfId-1119224"></a>
You can use the verification reports in HTML format to monitor the implementation run status and verification status when a batch script is running. The report updates after each implementation cellview run is completed so that you can monitor the progress. For details, see <a href="simulate.html#18287">&#8220;Scheduling Runs&#8221;</a>.</div>
<p>
<a id="pgfId-1115248"></a>To view the verification report, choose <em>Tools</em> &#8211; <em>Publish HTML Report</em>. This report lets you view the detailed verification status report in HTML format containing the overall verification and run status, requirement hierarchy with links and status, and the detailed verification status table of each requirement. </p>

<p>
<a id="pgfId-1115258"></a>A verification report includes the following elements:</p>
<ul><li>
<a id="pgfId-1115259"></a><strong>Report header</strong><br />
<a id="pgfId-1115260"></a>The header information includes the report filename, location, creation time, and name of the creator. It also includes the overall verification status. </li><li>
<a id="pgfId-1115266"></a><strong>Run information</strong><br />
<a id="pgfId-1115267"></a>The run information includes the implementation cellviews and their simulation details.</li><li>
<a id="pgfId-1115272"></a><strong>Requirements-based verification details</strong><br />
<a id="pgfId-1115273"></a>These verification details include the requirements, their verification status, and the implementation details with status. </li></ul>





<p>
<a id="pgfId-1137974"></a>The following is an example of the verification report in HTML format. </p>

<div class="webflare-div-image">
<img width="676" height="656" src="images/results-24.gif" /></div>

<p>
<a id="pgfId-1144747"></a>By default, the requirement IDs are hidden in the HTML report. You can display the requirement ID by setting the environment variable <a href="app_envar.html#73256">includeRequirementId</a> to <code>t </code>as shown in the following illustration<code>:</code></p>

<div class="webflare-div-image">
<img width="559" height="296" src="images/results-25.gif" /></div>

<p>
<a id="pgfId-1144319"></a>In a Verifier setup with referenced cellviews, the default behavior of the HTML report is to hide the ExtRef ID from the beginning of referenced implementation LCVH. You can display the ExtRef ID as shown in the following illustration by setting the environment variable <a href="app_envar.html#61449">includeReferenceIDPrefix</a> to <code>t</code>: <code></code></p>

<div class="webflare-div-image">
<img width="668" height="373" src="images/results-26.gif" /></div>
<br /><a href="#pagetop">Return to top</a><br /></div>
<!-- Begin Buttons --><!-- End Buttons -->
<footer><nav class="navigation"><b><em><a href="simulate.html" id="prev" title="Managing Implementation Runs">Managing Implementation Runs</a></em></b><b><em><a href="SLA_Verifier.html" id="nex" title="Verifying the Design Against the Specified Setup">Verifying the Design Against t ...</a></em></b></nav><div>
            For further assistance, contact <a href="https://support.cadence.com">Cadence Online Support</a>. Copyright &#169; 2020, <a href="https://www.cadence.com">Cadence Design Systems, Inc.</a> All rights reserved. 
          </div></footer>
</body></html>